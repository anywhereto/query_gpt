import express from 'express';
import cors from 'cors';
import dotenv from 'dotenv';
import OpenAI from 'openai';

dotenv.config();

const app = express();
const PORT = process.env.PORT || 3001;

// ä¸­é—´ä»¶
app.use(cors({
  origin: function (origin, callback) {
    // å…è®¸çš„æ¥æºåˆ—è¡¨
    const allowedOrigins = process.env.FRONTEND_URL 
      ? process.env.FRONTEND_URL.split(',').map(url => url.trim())
      : ['http://localhost:8080', 'http://localhost:5173', 'https://query-gpt.com'];
    
    // å…è®¸æ— æ¥æºçš„è¯·æ±‚ï¼ˆå¦‚ç§»åŠ¨åº”ç”¨ã€Postmanç­‰ï¼‰
    if (!origin) return callback(null, true);
    
    if (allowedOrigins.includes(origin)) {
      callback(null, true);
    } else {
      callback(new Error('ä¸å…è®¸çš„CORSæ¥æº'));
    }
  },
  credentials: true
}));
app.use(express.json());

// åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
const openai = new OpenAI({
  baseURL: "https://openrouter.ai/api/v1",
  apiKey: process.env.OPENROUTER_API_KEY,
  defaultHeaders: {
    "HTTP-Referer": process.env.SITE_URL || "https://query-gpt.com",
    "X-Title": process.env.SITE_NAME || "Query GPT",
  },
});

// å¯ç”¨æ¨¡å‹é…ç½®
const AVAILABLE_MODELS = {
  'deepseek-v3': 'deepseek/deepseek-chat-v3-0324:free',
  'gemini-2.0-flash': 'google/gemini-2.0-flash-thinking-exp-1219:free',
};

// ç”ŸæˆæŸ¥è¯¢çš„APIç«¯ç‚¹
app.post('/api/generate-query', async (req, res) => {
  try {
    const { question, databaseType, schema, aiModel } = req.body;

    // è¾“å…¥éªŒè¯
    if (!question || !databaseType || !aiModel) {
      return res.status(400).json({ 
        error: 'ç¼ºå°‘å¿…éœ€å‚æ•°: question, databaseType, aiModel' 
      });
    }

    // æ„å»ºç³»ç»Ÿæç¤º
    let systemPrompt = `You are a database expert. Convert the user's natural language question into a ${databaseType} query. 
Return ONLY the query code with no additional explanation or conversation.`;

    if (schema) {
      systemPrompt += `\n\nUse the following database schema for reference:\n${schema}`;
    }

    // è·å–æ¨¡å‹ID
    const modelId = AVAILABLE_MODELS[aiModel] || AVAILABLE_MODELS['deepseek-v3'];

    // è®°å½•è¯·æ±‚ä¿¡æ¯ï¼ˆä»…åœ¨å¼€å‘ç¯å¢ƒï¼‰
    if (process.env.NODE_ENV === 'development') {
      console.log('=== AI INPUT ===');
      console.log('System Prompt:', systemPrompt);
      console.log('User Question:', question);
      console.log('Model:', modelId);
    }

    const startTime = performance.now();

    // è°ƒç”¨OpenRouter API
    const completion = await openai.chat.completions.create({
      model: modelId,
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: question }
      ],
      temperature: 0.2,
      max_tokens: 1000,
    });

    const endTime = performance.now();
    const latency = endTime - startTime;

    // è®°å½•å“åº”ä¿¡æ¯ï¼ˆä»…åœ¨å¼€å‘ç¯å¢ƒï¼‰
    if (process.env.NODE_ENV === 'development') {
      console.log(`AI Response Latency: ${latency.toFixed(2)}ms`);
      console.log('=== AI OUTPUT ===');
      console.log('Generated Query:', completion.choices[0]?.message?.content);
    }

    const generatedQuery = completion.choices[0]?.message?.content?.trim() || '';

    res.json({ 
      query: generatedQuery,
      latency: Math.round(latency)
    });

  } catch (error) {
    console.error('Error generating query:', error);
    res.status(500).json({ 
      error: error.message || 'ç”ŸæˆæŸ¥è¯¢æ—¶å‘ç”Ÿé”™è¯¯' 
    });
  }
});

// å¥åº·æ£€æŸ¥ç«¯ç‚¹
app.get('/api/health', (req, res) => {
  res.json({ 
    status: 'OK', 
    timestamp: new Date().toISOString(),
    apiKeyConfigured: !!process.env.OPENROUTER_API_KEY
  });
});

// è·å–å¯ç”¨æ¨¡å‹
app.get('/api/models', (req, res) => {
  res.json({ models: Object.keys(AVAILABLE_MODELS) });
});

app.listen(PORT, () => {
  console.log(`ğŸš€ Server running on port ${PORT}`);
  console.log(`ğŸ“Š Health check: http://localhost:${PORT}/api/health`);
  
  if (!process.env.OPENROUTER_API_KEY) {
    console.warn('âš ï¸  Warning: OPENROUTER_API_KEY not set');
  }
});